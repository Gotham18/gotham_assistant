import os
import re
import json
import base64
from pathlib import Path
from typing import List, Dict, Any, Generator

import streamlit as st
from openai import OpenAI

# =====================
# App & Config
# =====================
APP_TITLE = "Gotham Assistant"
DATA_DIR = Path(".cache")
DATA_DIR.mkdir(exist_ok=True)

# ---------- Personal profile (updated: no longer a student) ----------
PROFILE = {
    "headline": "Data & AI professional with a foundation in research, analytics, and technology-driven strategy.",
    "roles": [
        "Research Consultant at Reach3 Insights",
        "Co-founder of an e-commerce brand called Nick&Jess, which ranked #10 on Amazon India in 2019"
    ],
    "specialties": [
        "Data Analysis", "AI & Automation", "Market Research",
        "Visualization", "Product Strategy"
    ],
    "skills": [
        "Python", "Streamlit", "SQL", "Power BI",
        "Machine Learning", "Q Research Software"
    ],
    "education": [
        "Applied AI Solutions Development â€“ George Brown College (2025)",
        "Data Science Certificate â€“ Brain Station (2023)",
        "Research Analyst Program â€“ Humber College (2022)",
        "B.Com (Financial Markets) â€“ Mumbai University (2017)"
    ],
   "entrepreneurial_experience": [
    "Co-founded an e-commerce brand that achieved a #10 ranking on Amazon IN, sharpening expertise in market dynamics, pricing strategy, and automation.",
    "Exited the business after COVID-19 due to limited experience scaling operations, transitioning into analytics and research to build deeper expertise."
],
"leadership_experience": [
    "At age 17, served as President of the Rotaract Club of his college, leading a 150+ member team.",
    "Organized and led multiple community service and skill-building initiatives during his tenure.",
    "Received the awards for Best President and Best Rotaract Club in the same year â€” a rare distinction.",
    "These experiences laid the foundation for his leadership style â€” collaborative, empathetic, and results-oriented.",
    "Later, as co-founder of Nick&Jess, he applied these skills to guide the brand to a #10 ranking on Amazon India."
],
"achievements": [
    "Co-founded an e-commerce brand that achieved a #10 ranking on Amazon IN.",
    "Recognized for leadership excellence and impact in youth community programs.",
    "Delivered multiple analytics projects driving business-level insights."
],
    "positioning": [
        "Combines business acumen with analytical depth to turn complex data into clear, actionable decisions."
    ],
    "focus": "Building scalable, AI-driven systems that deliver measurable impact.",
    "contact": {
        "linkedin": "https://www.linkedin.com/in/gothamtikyani/",
        "email": "[Reach out on LinkedIn for opportunities or collaborations.]"
    }
}



def _join(arr):
    return ", ".join(arr) if arr else ""

def build_profile_block(p: dict) -> str:
    def j(arr): return ", ".join(arr) if arr else ""
    contact = p.get("contact", {})
    linkedin = contact.get("linkedin", "")
    email = contact.get("email", "")
    return (
        f"Headline: {p.get('headline','')}\n"
        f"Roles: {j(p.get('roles',[]))}\n"
        f"Specialties: {j(p.get('specialties',[]))}\n"
        f"Core skills: {j(p.get('skills',[]))}\n"
        f"Education: {j(p.get('education',[]))}\n"
        f"Entrepreneurial experience: {p.get('entrepreneurial_experience','')}\n"
        f"Positioning: {p.get('positioning','')}\n"
        f"Focus: {p.get('focus','')}\n"
        f"LinkedIn: {linkedin}\n"
        f"Contact note: {email}"
    )


# =====================
# API Setup (Groq)
# =====================
GROQ_API_KEY = st.secrets.get("GROQ_API_KEY") or os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    st.error("Missing GROQ_API_KEY. Add it in Streamlit secrets or as an environment variable.")
    st.stop()

client = OpenAI(
    api_key=GROQ_API_KEY,
    base_url="https://api.groq.com/openai/v1"
)

# =====================
# Utilities
# =====================
def load_json(name: str):
    path = DATA_DIR / name
    if not path.exists():
        return {}
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return {}

def save_json(name: str, data: Dict[str, Any]):
    path = DATA_DIR / name
    path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

def soft_clip(text: str, limit: int | None) -> str:
    if not isinstance(text, str) or not limit or limit <= 0 or len(text) <= limit:
        return text
    cut = text[:limit].rsplit(" ", 1)[0]
    return (cut if cut else text[:limit]) + "â€¦"

# ==============
# Privacy helpers
# ==============
DEFAULT_KNOWN_CLIENTS: List[str] = st.secrets.get("KNOWN_CLIENTS", [])
CLIENT_ALIAS = "Fortune 500 brand"

EMAIL_REGEX = re.compile(r"([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,})")
PHONE_REGEX = re.compile(r"(\+?\d[\d\s().-]{7,}\d)")

def anonymize_known_clients(text: str, on: bool) -> str:
    if not on or not isinstance(text, str) or not DEFAULT_KNOWN_CLIENTS:
        return text
    out = text
    for name in DEFAULT_KNOWN_CLIENTS:
        if not name:
            continue
        pattern = re.compile(re.escape(name), re.IGNORECASE)
        out = pattern.sub(CLIENT_ALIAS, out)
    return out

def redact_pii(text: str) -> str:
    if not isinstance(text, str):
        return text
    text = EMAIL_REGEX.sub("[email hidden]", text)
    text = PHONE_REGEX.sub("[phone hidden]", text)
    return text

# =====================
# Prompting
# =====================
SYSTEM_PROMPT = (
    "You are Gotham Assistant â€” a personal AI version of Gotham Tikyani. "
    "Your job is to present Gothamâ€™s background, skills, projects, and achievements as an interactive rÃ©sumÃ©. "
    "Be friendly, confident, and concise (2â€“3 sentences unless asked for more). "
    "If someone asks how to contact Gotham, share his LinkedIn profile from the provided data. "
    "Never output placeholders like [insert ...] or TODOs; if info is missing, ask one brief clarifying question instead. "
    "When asked about any questions at the start, keep it vague and conversational which will lead to probing"
    "When asked about leadership or teamwork, include examples from his Rotaract presidency and entrepreneurial experience. "
    "When someone says 'Tell me about Gotham', treat it as the person, not the city from comics."
)


# ---------- Output cleaner to remove placeholders + avoid verbatim repeats ----------
PLACEHOLDER_RE = re.compile(r"\[insert[^]]*\]", re.IGNORECASE)
BLANKS_RE = re.compile(r"\n{3,}")

def clean_response(txt: str, last_answer: str | None) -> str:
    if not isinstance(txt, str):
        return txt
    txt = PLACEHOLDER_RE.sub("", txt)
    txt = BLANKS_RE.sub("\n\n", txt).strip()
    if last_answer and txt.strip() == last_answer.strip():
        txt = ("Hereâ€™s a quicker angle:\n"
               "- Iâ€™m Gothamâ€™s AI rÃ©sumÃ©.\n"
               "- I showcase skills, projects, and how I solve problems.\n"
               "- Ask about background, projects, or an example deliverable.")
    return txt

def build_api_messages(user_text: str, context_block: str, template_msg: str, history: List[Dict[str, str]]):
    messages: List[Dict[str, str]] = [{"role": "system", "content": SYSTEM_PROMPT}]
    # Always include the personal profile so the model has concrete facts
    messages.append({"role": "system", "content": "Personal profile:\n" + build_profile_block(PROFILE)})

    if context_block:
        messages.append({"role": "system", "content": f"Context for the task:\n{context_block}"})
    if template_msg:
        messages.append({"role": "system", "content": f"Follow this format when applicable:\n{template_msg}"})
    messages.extend(history)
    messages.append({"role": "user", "content": user_text})
    return messages

def stream_chat_completion(messages: List[Dict[str, str]]) -> str:
    """Stream from the API but buffer text; return a single final string (no double rendering)."""
    try:
        stream = client.chat.completions.create(
            model=st.session_state["openai_model"],
            messages=messages,
            stream=True,
            temperature=st.session_state.get("temperature", 0.5),
        )
        chunks = []
        for chunk in stream:
            delta = getattr(chunk.choices[0], "delta", None)
            if delta and getattr(delta, "content", None):
                chunks.append(delta.content)
        return "".join(chunks)
    except Exception as e:
        st.error("Issue talking to the model. Please try again.")
        st.caption(str(e))
        return ""

# =====================
# UI
# =====================
st.set_page_config(page_title=APP_TITLE, page_icon="ðŸ¤–")
st.title(APP_TITLE)

# Friendly intro on first load
st.session_state.setdefault("messages", [])
if not st.session_state["messages"]:
    st.info("ðŸ‘‹ Iâ€™m Gotham's Assistant â€” an interactive assistant. Ask about my background, skills, projects, or how I solve problems.")


with st.sidebar:
    st.subheader("Settings")
    # Groq-supported models (as of late 2025)
    st.session_state.setdefault("openai_model", "llama-3.1-8b-instant")
    st.session_state["openai_model"] = st.selectbox(
        "Model",
        options=[
            "llama-3.1-8b-instant",    # fast default
            "llama-3.3-70b-versatile", # larger, richer
            "gemma2-9b-it"             # smaller instruction-tuned
        ],
        index=0,
    )
    st.session_state["temperature"] = st.slider("Temperature", 0.0, 1.0, st.session_state.get("temperature", 0.5))
    anonymize_clients = st.toggle("Anonymize known clients", value=True, help="Redacts configured client names")
    cap_chars = st.number_input("Character cap (0 = off)", min_value=0, max_value=100000, value=0, step=100)

    if st.button("Reset chat", type="secondary"):
        st.session_state["messages"] = []
        st.rerun()

    st.caption("Known clients loaded from secrets: KNOWN_CLIENTS")


# Optional side context/template
with st.expander("Optional: Add context for the model"):
    context_block = st.text_area("Context", placeholder="Paste notes, data points, or a brief.", height=120)
with st.expander("Optional: Response template"):
    template_msg = st.text_area("Template", placeholder="e.g., Overview â†’ Insights â†’ Next steps", height=100)

MAX_HISTORY_TURNS = 12

# Show chat history
for m in st.session_state["messages"]:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# Input area
user_text = st.chat_input("Ask me anythingâ€¦")

if user_text:
    with st.chat_message("user"):
        st.markdown(user_text)

    history_only = [m for m in st.session_state["messages"] if m["role"] in ("user", "assistant")]
    trimmed_history = history_only[-MAX_HISTORY_TURNS:]

    api_messages = build_api_messages(
        user_text=user_text,
        context_block=context_block,
        template_msg=template_msg,
        history=trimmed_history
    )

    with st.chat_message("assistant"):
        raw = stream_chat_completion(api_messages) or ""

        if anonymize_clients:
            raw = anonymize_known_clients(raw, on=True)
        raw = redact_pii(raw)
        raw = soft_clip(raw, cap_chars)

        # Clean placeholders & avoid repeating last answer verbatim
        last_answer = next((m["content"] for m in reversed(st.session_state["messages"]) if m["role"] == "assistant"), "")
        response_text = clean_response(raw, last_answer)

        st.markdown(response_text)

        st.download_button(
            label="Download reply (.md)",
            data=response_text.encode("utf-8"),
            file_name="gotham_assistant_reply.md",
            mime="text/markdown",
        )

    st.session_state["messages"].extend([
        {"role": "user", "content": user_text},
        {"role": "assistant", "content": response_text},
    ])
